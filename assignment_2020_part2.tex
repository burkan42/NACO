% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
% A lot of package loading
\usepackage[pdftex]{graphicx}
\usepackage{geometry}
\usepackage[cmex10]{amsmath}
\usepackage{array, algpseudocode}
\usepackage{amsmath, amssymb, amsfonts, parskip, graphicx, verbatim}
\usepackage{url, hyperref}
\usepackage{bm, rotating, adjustbox, latexsym}
\usepackage{tabularx, booktabs}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\usepackage{float, setspace, mdframed}
\usepackage{color, contour, placeins, subfig, cite}
\usepackage[mathscr]{euscript}
\usepackage[osf]{mathpazo}
\usepackage{pgf, tikz, microtype, algorithm}
\usetikzlibrary{shapes,backgrounds,calc,arrows}
\usepackage{xcolor, colortbl, dsfont}


% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
\renewcommand\UrlFont{\color{blue}\rmfamily}

\graphicspath{{figures/}}

\begin{document}
%
\title{Practical Assignment Description / Template}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Natural Computing 2020/2021}
%
\authorrunning{NaCo 20/21}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Leiden Institute of Advanced Computer Science, The Netherlands}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Write a brief abstract \emph{about your paper}. This should at the very least mention your algorithm, brief mention of experiments and most important conclusion. Make sure to allocate enough time to writing this report!
\end{abstract}


\section{Introduction}
Introduce what \emph{this paper} (so not the reference paper) is about. Make sure to mention the assignment and your selected algorithm + reference(s), such as to the original paper on particle swarm optimization~\cite{eberhart1995particle}. If possible, place this work in some existing context, i.e. by referring to the EC bestiary or some overview paper like~\cite{Sorensen15}.

\section{Algorithm Description} \label{sec:description}
Give a general overview of the working principles of your algorithm. Make sure to always put quotation marks around animal names, and try to use strict mathematical formulations wherever possible. For example, you can introduce your algorithm by referring to 'bats', but afterwards you should refer to them as individuals or search-points. 

Make sure this description is \emph{complete}. It should explain all core concepts used in your algorithm, such that one should not need to refer back to the original paper to get the global picture of the working principals. If there are any parts of the algorithm which can not be described clearly based on the original paper, please contact the TAs for assistance.

\subsection{Comparison with standard algorithms}
Based on your description of the algorithm, which of the standard algorithms discussed in the course are the closest match to your algorithm? Describe the matching principles and where they diverge. Try to give some insight into how these differences might impact the behavior of the algorithms. What kind of functions would you predict this to matter most for, in either a positive or negative way?

% \subsection{(Optional) Usage of algorithms}
% If you have trouble dividing the work equally, you could have one team member take a look at where your algorithm has been used / cited in the past. This is optional, but could be nice to include for completeness. 

\section{Pseudo-code}\label{sec:pseudo}
Modify the pseudo-code given in Alg.~\ref{Alg:PSO}. \textbf{Do not deviate from the format used here!} Aim to be as precise as possible, and always use mathematical notation instead of referring to 'bats', 'chickens' etc. Make sure to follow the following notation conventions:
\begin{itemize}
    \item $n$: The dimensionality of the search space
    \item $M$: Number of individuals in set/array
    \item $\mathbf{x}=(x_1,x_2,\dots,x_n)$: A solution candidate from $\mathds{R}^n$
    \item $\mathbf{x}_i$: Solution candidate $i$ (for $i \in \{1\dots M\}$) in the set/array
    \item $f(\mathbf{x}_i)$: Objective function value of $\mathbf{x}_i$ ($f: \mathds{R}^n \rightarrow \mathds{R})$
    \item $\leftarrow$: Assignment operator
    \item $\bm{\mathcal{U}}(\mathbf{x}^{\text{min}},\mathbf{x}^{\text{max}} )$: Vector sampled uniformly at random. Here it is 'U' for uniform. For other distributions, use for example $\bm{\mathcal{N}}(0,1)$ for a single number sampled according to the \textit{normal} distribution with mean $0$ and variance $1$.
\end{itemize}

If you need to use any other notation, please be consistent and clearly define your added notation. In case of doubt, feel free to contact the TAs. 

Make sure to define any variables / functions you use. This can be done in the pseudocode itself or in a separate (sub)section of text.

Use numbered equations, such as Eq.~\ref{eq:abc} to easily refer back to complicated formulas within the pseudocode. 

\begin{equation}\label{eq:abc}
    a = b + c
\end{equation}

\vspace{-4mm} 
\begin{algorithm}[!ht]
\begin{algorithmic}[1]
	\For{$i = 1 \rightarrow M$}
		\State{$f^{\text{best}}_i \leftarrow f(\mathbf{x}_i), \quad \mathbf{x}_i \leftarrow \bm{\mathcal{U}}(\mathbf{x}^{\text{min}}, \mathbf{x}^{\text{max}}), \quad \mathbf{v}_i \leftarrow \bm{\mathcal{U}}(-v_{\text{max}}\mathbf{1}, v_{\text{max}}\mathbf{1})$} \Comment{Initialize} 
	\EndFor
	
	\While{termination criteria are not met}
		\For{$i = 1 \rightarrow M$}
			\State{$f_i \leftarrow f(\mathbf{x}_i)$}\Comment{Evaluate}
			\If{$f_i < f^{\text{best}}_i$}
				\State{$\mathbf{p}_i \leftarrow \mathbf{x}_i, \quad f^{\text{best}}_i \leftarrow f_i$}\Comment{Update personal best}
			\EndIf   
			\If{$f_i < f(\mathbf{g}_i)$}
				\State{$\mathbf{g}_i \leftarrow \mathbf{x}_i$} \Comment{Update global best}
			\EndIf  
			\State{Calculate $\mathbf{v}_i$ according to Eq.~\ref{eq:abc}}
			\State{$\mathbf{x}_{i} \leftarrow \mathbf{x}_{i} + \mathbf{v}_{i}$}  \Comment{Update position} 
		\EndFor
	\EndWhile
 \end{algorithmic}
\caption{Original Particle Swarm Optimization}
\label{Alg:PSO}
\end{algorithm}
\vspace{-2mm}

\subsection{Assumptions}
Clearly state all assumptions which are being made in your pseudocode. 
There are a few assumetions you always have to make:
\begin{itemize}
    \item You need to use minimization in the algorithm, but if the original paper deals with maximization, that should be mentioned here, including what you need to change to deal with this.
    \item The search space you need to deal with will be $[-5,5]^{n}$. Mention whether the original algorithm directly allows for this, or whether scaling is necessary.
    \item Your budget will be a maximum of $n \cdot 10000$ function evaluations. Many algorithms are specified with a limit on generations instead, so if this is the case, mention how you transform the budget. \footnote{A small discrepancy in budget is not critical, so you can use a fairly conservative conversion method if needed. As long as the difference is not much larger than the population size, this will not impact performance that much (but still mention it if you need to).} All analysis you do should be in terms of function evaluations (which will be tracked automatically), not generations.
\end{itemize}
If applicable, you should also mention all perceived vagueness in the original paper, parts of the original algorithm which are ambiguous, \dots and include how you resolved them to get the resulting pseudocode.

\emph{Everything up to this point should be included in part 1 of the assignment!} The deadline for this is 14/10/2020. More information about the submission is added in Section~\ref{sec:submission}. Please note that you are still allowed (and expected) to modify the content of the first sections based on the feedback you receive.

\section{Implementation}

You should implement your algorithm in python, using the IOHexperimenter~\cite{IOHprofiler} package. A skeleton implementation is provided in brightspace, as well as an implementation of random search which can be used for testing purposes. You can follow the steps in the provided python notebook to verify that the installation is working properly, and get some initial data to use. In case of issues, please do not hesitate to contact the TAs for assistance. 

When coding your algorithm, make sure to not use any hardcoded values. Instead, all of the parameters you use should be modifyable by the user, with set default values as the original paper (if you find other parameter settings to perform better, make sure to mention this explicitly). Include a table here, describing all parameters of your algorithm, their default values (both the default values as described in the original paper and the default values you implemented) and their range of accepted values. 

To verify whether your algorithm might work, you can call the function \verb!test_algorithm! provided in the notebook. \textbf{Passing this test is required for submission}, so if your algorithm fails this test, please contact the TAs. This function will then output the latex-code for a table, please include this table in this section, together with a brief description of your code (what classes / functions did you implement and which parts of the pseudocode do they correspond to). Make sure to mention any areas where there is a discrepancy between the pseudocode and the actual implementation!

\section{Experiments}
You should run your algorithm using the settings as provided in the notebook. This will run experiments on 24 functions from the COCO/BBOB~\cite{COCO} testbed, on instances 1-5, for dimensions 5 and 20, with 5 runs per instance. Note that this is quite an extensive experiment, so it might take some time to run (several hours at least), so test your algorithm first on a subset before running the full experiment.\footnote{It is recommended to use the available machines of the university to run these experiments. For more information go to LINK HERE}

\subsection{Original experiments}
Write a summary of the experiments performed in the original paper. Include which functions were used and which algorithms it was compared to (if any). If there are functions which are also included in the BBOB-suite (list of function descriptions can be found in~\cite{finck2010real}), compare their results to yours. If there are any discrepancies which can be explained, make sure to do so. If there are discrepancies which are not explainable, contact the TAs!

\section{Results}
Generate your figures using the IOHanalyzer. You are required to create at least an ECDF-plot (across all functions / dimensions) comparing your algorithm to the BIPOP-CMA-ES~\cite{COCOperformace} and the provided random search implementation (so all 3 in one figure!). For this comparison you can use the data for BIPOP-CMA-ES at \url{http://coco.gforge.inria.fr/data-archive/bbob/2009/BIPOP-CMA-ES_hansen_noiseless.tgz}.

For the remaining figures, you should judge which are most important by yourself. Attempt to highlight functions on which your algorithm performs particularly well / badly, and try to give some insight into why this happens. Make sure to provide interpretation of the data, so don't blindly add figures and tables. The discussion and interpretation of the results is the most important part of this paper! You need to let the reader know why the results you are showing matter, and explain how the algorithm can produce these results.

If you want to include additional figures / tables, you can add these to the appendix. Make sure to include detailed captions, as these figures / tables should be reasonably understood without constantly referring back to the main text.



\section{Conclusion}
Write a short conclusion summarizing the most important findings of this assignment:
\begin{itemize}
    \item How easy or difficult was it to reproduce the algorithm from the paper? Was there a lot of detail missing in the original paper? What is the effect of the assumptions you had to make?
    \item How original do you consider this algorithm to be compared to those studied in the course?
    \item Does the algorithm perform similarly to the performance claims from the original paper?
    \item How does the performance of the algorithm compare to the BIPOP-CMA-ES?
\end{itemize}


\section{Submission, review and grading}\label{sec:submission}
This assignment consists of two seperate submission stages. For the first stage, you should submit only Sections~\ref{sec:description} and ~\ref{sec:pseudo}. You should also include a brief introduction and abstract, which are \emph{not} the same as the final version, as you do not yet have all the content. Submission should be done via email to \href{mailto:NACO-TA@liacs.leidenuniv.nl}{\email{NACO-TA@liacs.leidenuniv.nl}}, and should only include your report in pdf format. You will then receive feedback on the submission. Make sure to incorporate this feedback, as this is only aimed to help you improve your final report! The deadline for this first stage is \textbf{14/10/2020}.

After completing your full report, you can submit it via \emph{EasyChair}: {link here}. You can update your submission until the deadline (\textbf{02/12/2020}), the last version will count. The deadline is \textbf{STRICT}, no submission will be possible after the deadline has passed! If you run into any issues, don't wait until the last day to contact the TAs! Make sure that all team members have created an account on easychair and can see the paper under their account.\footnote{If you already have a personal easychair account you can use this, but make sure it is clearly identifiable.}

After the deadline has passed, you will be asked to review two other papers. This will also be done through the easychair system. Make sure to leave a fair review and provide constructive comments. The reviews are individual, so don't coordinate with your team-members on this. The quality of your reviews will be taken into account for your final grade!

The criteria which you will use for reviewing are as follows:
\begin{itemize}
    \item General: Adherence to the report format, all sections filled with relevant content, clear and understandable language, overall technical soundness
\item Matching: The algorithm description matches as close as possible to the original paper, and any deviations made are clearly explained and argued for
\item Algorithm: Quality of the description and pseudocode, completeness (all working principles, parameters, assumptions and a comparison to existing algorithms discussed in the course are all clearly discussed)
\item Experimental results: The experiments are all described clearly and could be reproduced, results shown are relevant and discussed in the context of the project (so compared to state-of-the-art and randomsearch as provided)
\item Conclusion: The results obtained in the experiments are clearly discussed and the differences between algorithms is explained in sufficient detail.
\item Code quality: The code is sufficiently readable to be used to reproduce the experiments reported in the paper (comments, clear naming...)
\end{itemize}
Please take these criteria in mind when writing your report and code as well.

After the deadline for peer-reviewing (\textbf{16/12/2020}) has passed, we will review each paper and review. Since the reviews are individual, two members of the same team might receive somewhat different final grades. If the assignments are of sufficient quality, we will aim to include them in a future journal paper, and credit all team members, which will be beneficial for your academic profile.


\bibliographystyle{splncs04}
\bibliography{bibliography.bib}

\appendix
\section{Supplementary materials}
Next to submitting your assignment via easychair (as described in Section~\ref{sec:submission}, you should provide the following materials per email to \href{mailto:NACO-TA@liacs.leidenuniv.nl}{\email{NACO-TA@liacs.leidenuniv.nl}}: \begin{itemize}
    \item The python code of your algorithm. Use sufficient comments, modular coding style and clear variable names. This should be a single file which keeps the structure of the provided skeleton, and should be named \textit{GroupXX.py}. Running this file should benchmark the algorithm on all BBOB-functions, with the parameters you set as defaults. All parameters, including the ones determining the benchmark functions, should be passable as command-line arguments.\\
    \textit{Tip: You can use \url{https://git.liacs.nl} to host and share code with your teammates. You can log in using your ULCN username and password.}
    \item The runtime data generated by your code. This should be a single zip-file, containing only the data from your algorithm (set algorithm name property to \textit{GroupXX-Animal-Name}).
    % \item Per team member: In an email (to \href{mailto:NACO-TA@liacs.leidenuniv.nl}{\email{NACO-TA@liacs.leidenuniv.nl}}, subject line should include "[NaCo Assignment Review]" + your group number): a grade for your teammates based on their contribution, with some motivation. 
    \item This report in pdf format + the files used to generate it (tex, bib, figures). 
\end{itemize}


\end{document}