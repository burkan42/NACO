% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
% A lot of package loading
\usepackage[pdftex]{graphicx}
\usepackage{geometry}
\usepackage[cmex10]{amsmath}
\usepackage{array, algpseudocode}
\usepackage{amsmath, amssymb, amsfonts, parskip, graphicx, verbatim}
\usepackage{url, hyperref}
\usepackage{bm, rotating, adjustbox, latexsym}
\usepackage{tabularx, booktabs}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\usepackage{float, setspace, mdframed}
\usepackage{color, contour, placeins, subfig, cite}
\usepackage[mathscr]{euscript}
\usepackage[osf]{mathpazo}
\usepackage{pgf, tikz, microtype, algorithm}
\usetikzlibrary{shapes,backgrounds,calc,arrows}
\usepackage{xcolor, colortbl, dsfont}


% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
\renewcommand\UrlFont{\color{blue}\rmfamily}

\graphicspath{{figures/}}

\begin{document}
For the final grading of the reports, we use the same criteria as the students do in their peer-review. Make sure to be detailed, and aim to be constructive wherever possible. The criteria for grading are (please grade and motivate each point individually, out of 10):

\begin{enumerate}
    \item \textbf{Matching}. The algorithm description matches as close as possible to the original paper, and any deviations made are clearly explained and argued for
    \item \textbf{Algorithm}. Quality of the algorithm description and pseudocode, completeness (all working principles, parameters, assumptions and a comparison to existing algorithms discussed in the course are all clearly discussed).
    \item \textbf{Experimental results}. The experiments are all described clearly and could feasibly be reproduced, results shown are relevant and discussed in the context of the project (compared to the state-of-the-art and random-search).
    \item \textbf{Conclusions}. The results obtained in the experiments are clearly discussed and the differences between algorithms is explained in sufficient detail.	
    \item \textbf{Scientific writing style}. The scientific writing style consists of 4 main parts: 
    \begin{itemize}
        \item \textbf{Structure}. The report should be in the style of a scientific paper, so the language used should reflect this. This also implies that the report should be structured like a scientific paper (abstract, introduction, ..., conclusion), using the style from the template.
        \item \textbf{Citations}. Make sure the paper uses appropriate resources and cites them correctly and in full.
        \item \textbf{Consistency of formulation}. The paper should have internal consistency, especially in the formulation of variables, but also in terms of writing style.
        \item \textbf{Figures}. Figures are important tools to illustrate results whenever possible. These figures should all have a proper caption (so they can be understood on their own) and be properly referenced in the text (using label and ref commands). Either the figure should have proper labels for the axis or it should be made clear in the caption.
    \end{itemize}
    \item \textbf{Code}: (not included in student reviews) Don't go too in-depth, just try to judge the following:
    \begin{itemize}
        \item Code structure: How readable is the code. This means clear function/variables, enough comments etc.
        \item Code matching: Does the code roughly match what is written in the pseudocode? If there are large differences, this should be clearly motivated in their report.
        \item Correctness: Are there any obvious mistakes (e.g. maximization instead of minimization). Don't spend too much time on this, only look for very clear mistakes.
        \item Usability: How easy would it be to reuse this code later?
    \end{itemize}
\end{enumerate}

\section{Practical guidelines}
For reviewing the reviews, please use the template spreadsheet on ownCloud (use a new row for each review, there is a different sheet for each of you with the rows pre-filled). Here, the validity of the grade refers to whether or not it matches the quality of the report from 1 to 5 (so for example if the report is great while the review says it is awful, the validity of this grade is 1.) The validity is likely to be 5 most of the time. Quality of the review should be graded out of 5. Make sure your motivation is clear, but not too long (a paragraph or 2 at most).

Note that if you notice anything odd about the review on easyChair, please contact us directly and immediately. It seems like a few students might have had some technical issues and have written their review in the response field when accepting the review. It might be that they also filled in the form, but I'm not 100\% sure about that.

\end{document}

